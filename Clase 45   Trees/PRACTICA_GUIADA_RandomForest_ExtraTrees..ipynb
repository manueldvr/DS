{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PRACTICA_GUIADA_RandomForest_ExtraTrees..ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"IrvWOw0SqHjF","colab_type":"text"},"cell_type":"markdown","source":["# PRÁCTICA GUIADA: Random Forest y ExtraTrees en Scikit Learn\n","\n","## 1. Introducción\n","En esta práctica vamos a comparar el rendimiento de los siguientes algoritmos:\n","\n","- Árboles de decisión\n","- Bagging sobre Árboles de decisión\n","- Random Forest\n","- Extra Trees\n","\n","Para ello vamos a comenzar con la lectura del dataset de aceptabilidad de autos."]},{"metadata":{"id":"dBiqLbohqHjG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","df = pd.read_csv('car.csv') # Revisar el path\n","df.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GKu7LsGQqHjJ","colab_type":"text"},"cell_type":"markdown","source":["Esta vez vamos a codificar los atributos usando un esquema One Hot, es decir, los consideraremos como variables categóricas. También vamos a codificar el target usando el `LabelEncoder`."]},{"metadata":{"id":"homAEAkgqHjK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n","\n","lab_enc = LabelEncoder()\n","lab_enc.fit(df['acceptability'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qArdW1nIqHjM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["y = lab_enc.transform(df['acceptability'])\n","X = pd.get_dummies(df.drop('acceptability', axis=1))\n","\n","X.iloc[:,0:8].head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z79BxJwoqHjO","colab_type":"text"},"cell_type":"markdown","source":["Para que los resultados sean consistentes hay que exponer los modelos exactamente al mismo esquema de validación cruzada."]},{"metadata":{"id":"RAdhpVhmqHjP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from sklearn.model_selection import cross_val_score,StratifiedKFold\n","cv = StratifiedKFold(n_splits=3, random_state=41, shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"x-jXcU8mqHjR","colab_type":"text"},"cell_type":"markdown","source":["## 2. Comparando la performance de los árboles de decisión y ensambles de modelos\n"," \n","Ahora vamos a inicializar el clasificador de árbol de decisión, evaluar su rendimiento y compararlo con la perfomance de los ensambles que hemos visto hasta aquí. Para ello, vamos a usar los siguientes métodos:\n","\n","### RandomForestClassifier()\n","\n","Este método implementa y ejectua un RandomForest para resolver un problema de clasificación. Algunos de los parámetros más importantes son los siguientes:\n","\n","* `n_estimators`: el número de iteraciones (o sea, de `base_estimators`) para entrenar\n","* `criterion`: define el criterio de impureza para evaluar la calidad de las particiones (por defecto, es `gini`) \n","* `max_features`: la cantidad de features que extraerá para entrenar cada `base_estimator`. Por default es igual a `sqrt(X.shape[1])`\n","* `bootstrap` y `bootstrap_features`: controla si tanto los n_samples como las features son extraidos con reposición.\n","* `max_depth`: la pronfundidad máxima del árbol\n","* `min_samples_leaf`: el número mínimo de n_samples para constituir una hoja del árbol (nodo terminal)\n","* `min_samples_split`: el número mínimo de n_samples para realizar un split.\n","\n","y varios otros que pueden llegar a ser importantes al momento de realizar el tunning. En general, los más importantes suelen ser: `n_estimators`, `max_features`, `max_depth` y `min_samples_leaf`.\n","\n","\n","### ExtraTreesClassifier()\n","\n","Con este método se puede estimar un conjunto de conjuntos de árboles de decisión randomizados. Toma los mismos parámetros que `RandomForestClassifier()`.\n","\n","\n","### BaggingClassifier()\n","\n","Este método es muy interesante porque, a diferencia de los anteriores, es un \"meta estimador\", está situado en nivel de abstracción mayor. Es decir, que permite implementar el algoritmo de bagging (para clasificación) con casi cualquier estimador de Scikit-Learn. Toma como parámetros análogos a los dos métodos anteriores (con diferentes valores por defecto en algunos casos). Los únicos \"nuevos\" son: \n","\n","* `base_estimator`: el estimador sobre el cual queremos correr el bagging (regresiones, árboles, etc...)\n","* `max_samples`: la cantidad de n_samples que muestrea en cada iteración. Por default es igual a `sqrt(X.shape[0])`\n","\n","\n","Para comparar los diferentes algoritmos armamos la siguiente función. Toma como input un estimador y un string con el nombre que le quieran poner, y ejecuta un `cross_val_score`"]},{"metadata":{"id":"ngDW-gJjqHjR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n","\n","def evaluar_rendimiento(modelo, nombre):\n","    s = cross_val_score(modelo, X, y, cv=cv, n_jobs=-1)\n","    print(\"Rendimiento de {}:\\t{:0.3} ± {:0.3}\".format( \\\n","        nombre, s.mean().round(3), s.std().round(3)))\n","    \n","    \n","dt = DecisionTreeClassifier(class_weight='balanced')\n","\n","evaluar_rendimiento(dt,\"Árbol de decisión\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5ig31YKwqHjT","colab_type":"text"},"cell_type":"markdown","source":["Ahora intenten ustedes con los modelos restantes y evalúen el rendimiento.  \n"," * Bagging de Árboles de decisión\n"," * RandomForest\n"," * ExtraTrees\n","\n","Sería recomendable que vean la documentación para ver qué parámetros aceptan.   \n","http://scikit-learn.org/stable/modules/ensemble.html#forest"]},{"metadata":{"id":"GJ6hIIF8qHjT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["bdt = BaggingClassifier(DecisionTreeClassifier())\n","rf = RandomForestClassifier(class_weight='balanced')\n","et = ExtraTreesClassifier(class_weight='balanced')\n","\n","evaluar_rendimiento(dt,  \"Árbol de decisión\")\n","evaluar_rendimiento(bdt, \"Bagging AD\")\n","evaluar_rendimiento(rf,  \"Random Forest\")\n","evaluar_rendimiento(et,  \"Extra Trees\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-05k28xpqHjV","colab_type":"text"},"cell_type":"markdown","source":["En este caso, el bagging de árboles de decisión anda mejor que el resto.   \n","Con otros set de datos, los modelos Random Forest y Extra Trees podrían tener mejores resultados y merecen ser probados. Podríamos implementar un gridsearh para intentar realizar un tunning de los hiperparámetros..."]},{"metadata":{"id":"qpVXjHOuqHjW","colab_type":"text"},"cell_type":"markdown","source":["## 3. Tuneando los hiperparámetros de RandomForest"]},{"metadata":{"id":"hJhtB6VaqHjW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","param_trees = {'n_estimators': [50, 100, 200], \n","               'max_features': [1, 5, 8, 10, 21], \n","               'max_depth': [5, 20, 50, 70, 100], \n","               'min_samples_leaf':[1, 5, 8, 10, 50]}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JxK_BBFvqHja","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["rf = RandomForestClassifier(class_weight='balanced')\n","kf = StratifiedKFold(n_splits=3, shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sRL4LTxXqHjc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["grid_search_rf = GridSearchCV(rf, param_grid=param_trees, cv=kf, verbose=1, n_jobs=3)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Or4giEHtqHje","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["grid_search_rf.fit(X, y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5Hz8ks9NqHjg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["grid_search_rf.best_estimator_"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CX-uaWqtqHjh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["grid_search_rf.best_score_"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yskfVadjqHjl","colab_type":"text"},"cell_type":"markdown","source":["Puede verse que realizando un proceso de tunnig es ahora RandomForest el algoritmo que mejora la perfomance de los clasificadores comparados."]},{"metadata":{"id":"NdGadx5zqHjl","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}